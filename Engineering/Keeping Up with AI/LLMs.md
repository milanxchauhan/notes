### What are LLMs?

Paper - [Understanding LLMs: A Comprehensive Overview from Training to Inference](https://arxiv.org/abs/2401.02038) 
Understand the Transformer model architecture - [Attention is all you need](int n = S.length(); for (int i = 0; i < n / 2; i++) { swap(S[i], S[n - i - 1]); } return S;)
How to get perfect JSON output from LLMs? - https://github.com/1rgs/jsonformer/
Finetuning LLMs - [The Novice's LLM Training Guide](https://rentry.org/llm-training)
Comprehensive list of LLM evals - https://usescholar.org/evals
Jeremy Howard's lecture on LLMs - [A Hacker's Guide to Language Models](https://youtu.be/jkrNMKz9pWU?si=4PPF5-s4owQP6wCW)

### Understanding context windows
- GPT 4 - 8K - 128K tokens
- Claude 3 - "The Claude 3 family of models will initially offer a 200K context window upon launch. However, all three models are capable of accepting inputs exceeding 1 million tokens and we may make this available to select customers who need enhanced processing power."

- Processing longer context prompts require the models to have robust [recall properties](obsidian://open?vault=notes&file=Engineering%2FAll%20things%20AI%2FNIAH%20Evaluation).